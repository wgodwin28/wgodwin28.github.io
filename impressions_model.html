<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Will Godwin" />


<title>Predicting Impressions</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->





<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="projects.html">Data Projects</a>
</li>
<li>
  <a href="papers.html">Papers</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/wgodwin28">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/will-godwin-03a106150/">
    <span class="fa fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Predicting Impressions</h1>
<h4 class="author"><em>Will Godwin</em></h4>
<h4 class="date"><em>9/2/2019</em></h4>

</div>


<p>The goal is to build a model that predicts “impressions”, or the number of people the ad reached, using relevant advertisement covariates. I’ll use political advertisement spending data released by google. The dataset contains over 200,000 unique ads since June 2018 with relevant metadata including <em>number of impressions</em> as a ordinal categorical variable. The covariates I’ll use to predict impressions are: <em>ad type</em> (text, video, or image), <em>region the ad was showed</em> (U.S. or E.U.), <em>number of days the ad aired</em>, and <em>lower/upper bounds on dollars spent for the ad</em>. The first step is understanding the univariate distributions and basic bivariate relationships.</p>
<div id="data-exploration" class="section level2">
<h2>Data Exploration</h2>
<p>I’ve already loaded in the data and done a little preprocessing to convert variables to the correct classes and drop all irrelevant columns.</p>
<pre class="r"><code>#impressions
ggplot(dt, aes(Impressions)) +
  geom_bar() +
  geom_text(stat = &#39;count&#39;, aes(label = percent(..count../nrow(dt)), vjust = -0.2)) +
  theme_bw()</code></pre>
<p><img src="impressions_model_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Most ads are classified under the “Under 10k” category, indicating an imbalanced classification problem. Due to this imbalance, I’ll plot impression counts on the log scale to observe differences at smaller frequecies.</p>
<pre class="r"><code>#time series plot of ad counts across impression category
dt %&gt;%
  group_by(date=as.Date(week_start), Impressions) %&gt;%
  summarize(weekly_ad_count=n()) %&gt;%
  ggplot(aes(date, weekly_ad_count, color=Impressions)) +
    geom_point() +
    xlab(&quot;Date&quot;) +
    ylab(&quot;Number of Ads (on log scale)&quot;) +
    geom_vline(xintercept = as.Date(&quot;2018/11/06&quot;), linetype=4) +
    geom_text(aes(x=as.Date(&quot;2018/10/28&quot;), y=6400, label=&quot; Midterm&quot;), 
              colour=&quot;blue&quot;, angle=90, text=element_text(size=11)) +
    scale_y_log10() +
    scale_x_date(labels = date_format(&quot;%m/%Y&quot;), breaks = date_breaks(&quot;2 month&quot;)) +
    scale_color_discrete(name = &quot;Impressions&quot;) +
    theme_bw()</code></pre>
<p><img src="impressions_model_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>In order to assess whether start date may be related to number of impressions, I first aggregated the number of ads by week and impression category. Then I plotted the number of ads across the full time series and colored by impression category. One takeaway from this plot is a clear relationship between number of ads and ad start date. Ad counts, regardless of impression category, appear to increase up the the 2018 midterm election</p>
<p>Now I’ll make a similar plot across region of the world. Note that I chose to plot these frequencies on a log 10 scale in order to illustrate relative frequencies within the lower frequency categories (100k-1M impressions, etc)</p>
<pre class="r"><code>#plot impression counts by region
ggplot(dt, aes(Impressions, fill=Region)) +
  geom_bar() +
  scale_y_log10() +
  ylab(&quot;Count (log 10 scale)&quot;) +
  theme_bw()</code></pre>
<p><img src="impressions_model_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The EU has fewer ads within each category and appears to have a greater proportion of its ads with &gt;10k impressions compared to the U.S., which indicates that this variable may be a useful covariate in the model.</p>
<pre class="r"><code>#plot impression counts by type of ad
ggplot(dt, aes(Impressions, fill=Ad_Type)) +
  geom_bar() +
  scale_y_log10() +
  ylab(&quot;Count (log 10 scale)&quot;) +
  theme_bw()</code></pre>
<p><img src="impressions_model_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>I create a “number of days running” variable by combining the ad start date and ad end date, and plot that against number of impressions using a box and whiskers plot.</p>
<pre class="r"><code>dt %&gt;%
  mutate(days_running=difftime(Date_Range_End, Date_Range_Start, units = &quot;days&quot;)) %&gt;%
  ggplot(aes(Impressions, days_running)) +
    geom_boxplot() +
    ylab(&quot;Number of Days Ad Ran&quot;) +
    theme_bw()</code></pre>
<p><img src="impressions_model_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Looking across the central tendency for each impression category, we see indication of a potential trend: as ad air time increases so does the number of impressions.</p>
<pre class="r"><code>#create model data frame for ease of use
dt.mod &lt;- dt %&gt;%
  select(Impressions, Num_of_Days, Region, Ad_Type, Spend_Range_Min_USD)

#extract the response and predictors for ease of use
x&lt;-dt.mod[,2:5]
y&lt;-dt.mod[,1]
form &lt;- as.formula(Impressions ~ Num_of_Days + Region + Ad_Type + Spend_Range_Min_USD)</code></pre>
</div>
<div id="modelling" class="section level2">
<h2>Modelling</h2>
<div id="multinomial-logistic" class="section level3">
<h3>Multinomial logistic</h3>
<pre class="r"><code>#Build the model
model1 &lt;- vglm(formula = form, 
             data=dt.mod, family=&quot;multinomial&quot;)

#extract model summary
#summary(model1)

#Predict using the model
probability&lt;-predict(model1,x,type=&quot;response&quot;)
dt.mod &lt;- dt.mod %&gt;%
  mutate(predicted_cat = apply(probability,1,which.max),
         predicted_name = case_when(predicted_cat==1 ~ &quot;Under 10k&quot;,
                                    predicted_cat==2 ~ &quot;10k-100k&quot;,
                                    predicted_cat==3 ~ &quot;100k-1M&quot;,
                                    predicted_cat==4 ~ &quot;1M-10M&quot;,
                                    predicted_cat==5 ~ &quot;10M+&quot;),
         predicted_name = factor(predicted_name, 
                                 levels = c(&quot;Under 10k&quot;, &quot;10k-100k&quot;, &quot;100k-1M&quot;, &quot;1M-10M&quot;, &quot;10M+&quot;)))

#Accuracy of the model
mtab &lt;- table(dt.mod$predicted_name,dt.mod$Impressions)
library(caret)
confusionMatrix(mtab)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            
##             Under 10k 10k-100k 100k-1M 1M-10M   10M+
##   Under 10k    158390    16801    2244     28      0
##   10k-100k       2551    14884    4646    317      2
##   100k-1M          12     2511    8118   1888    218
##   1M-10M            0        0     129    255     34
##   10M+              0        0       0     13     39
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8527          
##                  95% CI : (0.8512, 0.8542)
##     No Information Rate : 0.7554          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.5787          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Under 10k Class: 10k-100k Class: 100k-1M
## Sensitivity                    0.9841         0.43526        0.53630
## Specificity                    0.6341         0.95798        0.97661
## Pos Pred Value                 0.8925         0.66446        0.63686
## Neg Pred Value                 0.9280         0.89872        0.96496
## Prevalence                     0.7554         0.16048        0.07104
## Detection Rate                 0.7433         0.06985        0.03810
## Detection Prevalence           0.8328         0.10512        0.05982
## Balanced Accuracy              0.8091         0.69662        0.75646
##                      Class: 1M-10M Class: 10M+
## Sensitivity               0.101959    0.133106
## Specificity               0.999226    0.999939
## Pos Pred Value            0.610048    0.750000
## Neg Pred Value            0.989439    0.998808
## Prevalence                0.011737    0.001375
## Detection Rate            0.001197    0.000183
## Detection Prevalence      0.001962    0.000244
## Balanced Accuracy         0.550593    0.566522</code></pre>
<p>Confusion matrix shows the model predictions (row-wise) stacked against the actual data (column-wise). If the model fit the data perfectly, we’d only see values along the diagonal and would see zeros everywhere else. The overall accuracy is 85%, which means that the model gets the prediction correct 85% of the time. Sensitivity (or recall) and specificity varies across the impression categories, as we’d expect. When predicting “Under 10k” impressions, a sensitivity of 0.98 indicates that for all the actual “Under 10k” ads the model correctly labels the data 98% of the time. The relatively poor specificity indicates that the model correctly predicts that an ad will NOT get “Under 10k” impressions 63% of the time. We see the opposite result from the “10M+” impressions category. Because we have an imbalanced classification problem with so few “10M+” impression ads, the model can predict that an ad will not get “10M+” impressions with 99.99% confidence. However, the sensitivity of 0.13 tells us that 87% of actual “10M+” impression ads are incorrectly labeled by the model.</p>
<p>Model evaluation can be based on overall accuracy of the model or on more specific metrics, depending on the research question. For instance, consider a wealthy, politically-minded business with the goal of running ads that reach as many people as possible. They could start with looking at what covariates are conditionally associated with number of impressions from the model coefficients and infer that as number of days aired increases, so does the number of impressions. Going even further, they could build a model that optimizes for their main goal-accurately predicting ads with millions of impressions. As we noted, the logistic model above does a poor job at this, since it correctly labels a “1-10M” impression ad only 10% of the time and a “10M+” impression ad only 13% of the time. Let’s see if we can improve the accuracy for this specific case using a random forest model.</p>
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<pre class="r"><code>#Build the model-needed to ensure all categorical variables were factors above
model3 &lt;- randomForest(form, data=dt.mod)

#Summarize the model
summary(model3)</code></pre>
<pre><code>##                 Length  Class  Mode     
## call                  3 -none- call     
## type                  1 -none- character
## predicted        213080 factor numeric  
## err.rate           3000 -none- numeric  
## confusion            30 -none- numeric  
## votes           1065400 matrix numeric  
## oob.times        213080 -none- numeric  
## classes               5 -none- character
## importance            4 -none- numeric  
## importanceSD          0 -none- NULL     
## localImportance       0 -none- NULL     
## proximity             0 -none- NULL     
## ntree                 1 -none- numeric  
## mtry                  1 -none- numeric  
## forest               14 -none- list     
## y                213080 factor numeric  
## test                  0 -none- NULL     
## inbag                 0 -none- NULL     
## terms                 3 terms  call</code></pre>
<pre class="r"><code>#Predict using the model
dt.mod$pred_randomforest &lt;- predict(model3, x)

#Accuracy of the model
mtab3 &lt;- table(dt.mod$pred_randomforest, dt.mod$Impressions)
confusionMatrix(mtab3)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            
##             Under 10k 10k-100k 100k-1M 1M-10M   10M+
##   Under 10k    158816    17120    2286     28      0
##   10k-100k       2116    14269    4010    306      2
##   100k-1M          21     2803    8620   1697    121
##   1M-10M            0        4     214    468     83
##   10M+              0        0       7      2     87
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8554          
##                  95% CI : (0.8539, 0.8569)
##     No Information Rate : 0.7554          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.5844          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Under 10k Class: 10k-100k Class: 100k-1M
## Sensitivity                    0.9867         0.41727        0.56947
## Specificity                    0.6272         0.96403        0.97655
## Pos Pred Value                 0.8910         0.68922        0.64998
## Neg Pred Value                 0.9386         0.89642        0.96739
## Prevalence                     0.7554         0.16048        0.07104
## Detection Rate                 0.7453         0.06697        0.04045
## Detection Prevalence           0.8365         0.09716        0.06224
## Balanced Accuracy              0.8070         0.69065        0.77301
##                      Class: 1M-10M Class: 10M+
## Sensitivity               0.187125   0.2969283
## Specificity               0.998571   0.9999577
## Pos Pred Value            0.608583   0.9062500
## Neg Pred Value            0.990424   0.9990328
## Prevalence                0.011737   0.0013751
## Detection Rate            0.002196   0.0004083
## Detection Prevalence      0.003609   0.0004505
## Balanced Accuracy         0.592848   0.6484430</code></pre>
<p>Compared to multinomial logistic regression, random forest does produce higher sensitivity for lower frequency classes like “1-10M” and “10M+”. However, most business execs wouldn’t be happy with a model that correctly labels an ad to get “10M+” impressions only 30% of the time. The overall accuracy of the model is similar to the logisitic regression at 85%, indicating that the gains made in sensitivity for high impression classes may have come at cost for other components of model accuracy. Lastly, I’ll test the performance of support vector machine.</p>
</div>
<div id="boosted-c5.0" class="section level3">
<h3>Boosted C5.0</h3>
<pre class="r"><code>#Build the model
model4 &lt;- C5.0(form, data=dt.mod, trials=8)

#Predict using the model
dt.mod$pred_c50 &lt;- predict(model4, x)

#Accuracy of the model
mtab5 &lt;- table(dt.mod$pred_c50, dt.mod$Impression)
confusionMatrix(mtab5)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            
##             Under 10k 10k-100k 100k-1M 1M-10M   10M+
##   Under 10k    156402    15054    2147     28      0
##   10k-100k       4417    13170    1929    125      2
##   100k-1M         134     5971   11020   2267    237
##   1M-10M            0        1      41     80     20
##   10M+              0        0       0      1     34
## 
## Overall Statistics
##                                           
##                Accuracy : 0.8481          
##                  95% CI : (0.8465, 0.8496)
##     No Information Rate : 0.7554          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.5816          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Under 10k Class: 10k-100k Class: 100k-1M
## Sensitivity                    0.9717         0.38513        0.72802
## Specificity                    0.6695         0.96381        0.95651
## Pos Pred Value                 0.9008         0.67047        0.56141
## Neg Pred Value                 0.8846         0.89130        0.97872
## Prevalence                     0.7554         0.16048        0.07104
## Detection Rate                 0.7340         0.06181        0.05172
## Detection Prevalence           0.8149         0.09219        0.09212
## Balanced Accuracy              0.8206         0.67447        0.84226
##                      Class: 1M-10M Class: 10M+
## Sensitivity              0.0319872   0.1160410
## Specificity              0.9997056   0.9999953
## Pos Pred Value           0.5633803   0.9714286
## Neg Pred Value           0.9886305   0.9987843
## Prevalence               0.0117374   0.0013751
## Detection Rate           0.0003754   0.0001596
## Detection Prevalence     0.0006664   0.0001643
## Balanced Accuracy        0.5158464   0.5580181</code></pre>
<p>A Boosted C5.0 model is based on simple tree-based framework that uses boosting methods. While a random forest splits the predictor space on independent trees into partitions that minimize impurity/maximize information criterion, boosting models grow trees sequentially with the residuals of the previous tree becoming the response variable of the subsequent tree. While this smoothing over residuals may improve model performance in some situations, in this context, the random forest performed slightly better overall.</p>
</div>
</div>
<div id="model-evaluation" class="section level2">
<h2>Model Evaluation</h2>
<p>True model evaluation requires testing the predictions on data not used in the model. These results are coming soon!</p>
</div>
<div id="model-inference-and-functionality" class="section level2">
<h2>Model Inference and Functionality</h2>
<p>Coming Soon!</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
